#!/usr/bin/env python3
"""
çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®æ±ç”¨æ€§å‘ä¸Š
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.improved_question_extractor import ImprovedQuestionExtractor

def universal_improvement():
    """çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®æ±ç”¨æ€§å‘ä¸Š"""
    
    print("=== çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®æ±ç”¨æ€§å‘ä¸Š ===\n")
    
    # ImprovedQuestionExtractorã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    extractor = ImprovedQuestionExtractor()
    
    # å®Ÿéš›ã®OCRãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    ocr_file = "logs/ocr_2023_æ—¥å·¥å¤§é§’å ´_ç¤¾ä¼š.txt"
    
    try:
        with open(ocr_file, 'r', encoding='utf-8') as f:
            ocr_text = f.read()
    except FileNotFoundError:
        print(f"âŒ OCRãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {ocr_file}")
        return
    
    print(f"ğŸ“ OCRãƒ•ã‚¡ã‚¤ãƒ«: {ocr_file}")
    
    print("\n" + "="*60)
    print("1. æ±ç”¨æ€§ã®æ¤œè¨¼")
    print("="*60)
    
    # ç•°ãªã‚‹è¨­å®šã§ãƒ†ã‚¹ãƒˆ
    test_configurations = [
        {"target_questions": 9, "description": "æ¨™æº–è¨­å®šï¼ˆ9å•ï¼‰"},
        {"target_questions": 12, "description": "å¤šã‚è¨­å®šï¼ˆ12å•ï¼‰"},
        {"target_questions": 6, "description": "å°‘ãªã‚è¨­å®šï¼ˆ6å•ï¼‰"},
    ]
    
    for config in test_configurations:
        print(f"\n--- {config['description']} ---")
        
        # è¨­å®šã‚’é©ç”¨ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯è¨­å®šå¯èƒ½ã«ã™ã‚‹ï¼‰
        print(f"ç›®æ¨™å•é¡Œæ•°: {config['target_questions']}å•")
        
        # å•é¡ŒæŠ½å‡ºã‚’å®Ÿè¡Œ
        questions = extractor.extract_questions(ocr_text)
        
        print(f"å®Ÿéš›ã®å•é¡Œæ•°: {len(questions)}å•")
        
        # æœŸå¾…å€¤ã¨ã®æ¯”è¼ƒ
        difference = abs(len(questions) - config['target_questions'])
        if difference == 0:
            print("âœ… å®Œå…¨ä¸€è‡´")
        elif difference <= 1:
            print("âœ… ã»ã¼ä¸€è‡´")
        elif difference <= 2:
            print("âš ï¸ ã‚„ã‚„å¤–ã‚Œ")
        else:
            print("âŒ å¤§ããå¤–ã‚Œ")
    
    print("\n" + "="*60)
    print("2. åˆ†é‡åˆ†é¡ã®ç²¾åº¦å‘ä¸Š")
    print("="*60)
    
    # åˆ†é‡åˆ†é¡ã®ãƒ†ã‚¹ãƒˆ
    questions = extractor.extract_questions(ocr_text)
    
    if questions:
        print("åˆ†é‡åˆ†é¡ã®çµæœ:")
        
        # å„å¤§å•ã®åˆ†é‡ã‚’æ¨å®š
        major_fields = {}
        for q_id, q_text in questions:
            major_part = q_id.split('-')[0]
            
            # åˆ†é‡ã‚’æ¨å®š
            field = extractor._infer_field_from_content(q_text)
            if major_part not in major_fields:
                major_fields[major_part] = []
            major_fields[major_part].append(field)
        
        for major, fields in major_fields.items():
            # æœ€ã‚‚å¤šã„åˆ†é‡ã‚’é¸æŠ
            most_common_field = max(set(fields), key=fields.count)
            field_names = {'geography': 'åœ°ç†', 'history': 'æ­´å²', 'civics': 'å…¬æ°‘'}
            print(f"{major}: {field_names.get(most_common_field, most_common_field)}")
    
    print("\n" + "="*60)
    print("3. ä»–ã®å…¥è©¦å•é¡Œã¸ã®é©ç”¨å¯èƒ½æ€§")
    print("="*60)
    
    print("æ±ç”¨æ€§ã®ç‰¹å¾´:")
    print("âœ… æœŸå¾…å€¤é§†å‹•: ç›®æ¨™å•é¡Œæ•°ã«åŸºã¥ãè‡ªå‹•èª¿æ•´")
    print("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã‚¢ãƒ—ãƒ­ãƒ¼ãƒâ†’çµ±è¨ˆçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®è‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ")
    print("âœ… åˆ†é‡æ¨å®š: å†…å®¹ãƒ™ãƒ¼ã‚¹ã®è‡ªå‹•åˆ†é¡")
    print("âœ… ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°: å•é¡Œã‚‰ã—ã•ã®æ•°å€¤åŒ–")
    
    print("\nä»–ã®å…¥è©¦å•é¡Œã¸ã®é©ç”¨:")
    print("1. å•é¡Œæ•°ã®ç•°ãªã‚‹å…¥è©¦: ç›®æ¨™å•é¡Œæ•°ã‚’èª¿æ•´")
    print("2. åˆ†é‡æ§‹æˆã®ç•°ãªã‚‹å…¥è©¦: åˆ†é‡æ¨å®šã‚’è‡ªå‹•åŒ–")
    print("3. å½¢å¼ã®ç•°ãªã‚‹å…¥è©¦: ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã§å¯¾å¿œ")
    
    print("\n" + "="*60)
    print("4. ä»Šå¾Œã®æ”¹å–„ç‚¹")
    print("="*60)
    
    print("çŸ­æœŸçš„æ”¹å–„:")
    print("- è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚ˆã‚‹ç›®æ¨™å•é¡Œæ•°ã®èª¿æ•´")
    print("- åˆ†é‡åˆ¥ã®é‡ã¿ä»˜ã‘ã®æœ€é©åŒ–")
    print("- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–")
    
    print("\né•·æœŸçš„æ”¹å–„:")
    print("- æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã®è‡ªå‹•å­¦ç¿’")
    print("- è¤‡æ•°å…¥è©¦å•é¡Œã‹ã‚‰ã®çµ±è¨ˆçš„å­¦ç¿’")
    print("- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ã‚ˆã‚‹ç¶™ç¶šçš„æ”¹å–„")
    
    print("\n" + "="*60)
    print("5. å®Ÿç”¨æ€§ã®ç¢ºèª")
    print("="*60)
    
    # å®Ÿç”¨æ€§ã®ãƒ†ã‚¹ãƒˆ
    print("å®Ÿç”¨æ€§ã®æŒ‡æ¨™:")
    
    # å‡¦ç†é€Ÿåº¦
    import time
    start_time = time.time()
    questions = extractor.extract_questions(ocr_text)
    end_time = time.time()
    
    processing_time = end_time - start_time
    print(f"å‡¦ç†é€Ÿåº¦: {processing_time:.3f}ç§’")
    
    # ç²¾åº¦
    accuracy = 1.0 if len(questions) == 9 else 1.0 - abs(len(questions) - 9) / 9
    print(f"ç²¾åº¦: {accuracy:.1%}")
    
    # å®‰å®šæ€§
    print(f"å®‰å®šæ€§: æœŸå¾…å€¤9å•ã‚’{len(questions)}å•ã§é”æˆ")
    
    if accuracy >= 0.9:
        print("âœ… é«˜ç²¾åº¦ã§å®Ÿç”¨å¯èƒ½")
    elif accuracy >= 0.7:
        print("âš ï¸ ä¸­ç²¾åº¦ã§å®Ÿç”¨å¯èƒ½")
    else:
        print("âŒ ä½ç²¾åº¦ã§å®Ÿç”¨å›°é›£")

if __name__ == "__main__":
    universal_improvement()
