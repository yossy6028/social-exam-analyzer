#!/usr/bin/env python3
"""
å®Ÿéš›ã®OCRãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã§å•é¡ŒæŠ½å‡ºå™¨ã‚’ãƒ†ã‚¹ãƒˆ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.improved_question_extractor import ImprovedQuestionExtractor
from modules.theme_extractor_v2 import ThemeExtractorV2

def test_full_ocr():
    """å®Ÿéš›ã®OCRãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã§ãƒ†ã‚¹ãƒˆ"""
    
    print("=== å®Ÿéš›ã®OCRãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã§ã®ãƒ†ã‚¹ãƒˆ ===\n")
    
    # å®Ÿéš›ã®OCRãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    ocr_file = "logs/ocr_2023_æ—¥å·¥å¤§é§’å ´_ç¤¾ä¼š.txt"
    
    if not os.path.exists(ocr_file):
        print(f"âŒ OCRãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {ocr_file}")
        return
    
    print(f"ğŸ“ OCRãƒ•ã‚¡ã‚¤ãƒ«: {ocr_file}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    with open(ocr_file, 'r', encoding='utf-8') as f:
        ocr_text = f.read()
    
    print(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(ocr_text)} æ–‡å­—")
    print(f"ğŸ“ è¡Œæ•°: {len(ocr_text.split(chr(10)))} è¡Œ")
    
    print("\n" + "="*50)
    print("å•é¡ŒæŠ½å‡ºã®ãƒ†ã‚¹ãƒˆ:")
    
    # å•é¡ŒæŠ½å‡ºå™¨ã§ãƒ†ã‚¹ãƒˆ
    extractor = ImprovedQuestionExtractor()
    questions = extractor.extract_questions(ocr_text)
    
    print(f"æŠ½å‡ºã•ã‚ŒãŸå•é¡Œæ•°: {len(questions)}")
    print("\nå„å•é¡Œã®è©³ç´°:")
    
    for i, (q_id, q_text) in enumerate(questions, 1):
        print(f"\n{i}. {q_id}")
        print(f"   ãƒ†ã‚­ã‚¹ãƒˆ: {q_text[:100]}...")
    
    # å¤§å•æ§‹é€ ã®åˆ†æ
    print("\n" + "="*50)
    print("å¤§å•æ§‹é€ ã®åˆ†æ:")
    
    major_sections = {}
    for q_id, _ in questions:
        major_part = q_id.split('-')[0]
        major_sections[major_part] = major_sections.get(major_part, 0) + 1
    
    for major, count in major_sections.items():
        print(f"{major}: {count}å•")
    
    print(f"\nç·å¤§å•æ•°: {len(major_sections)}")
    print(f"ç·å•é¡Œæ•°: {len(questions)}")
    
    # æœŸå¾…å€¤ã¨ã®æ¯”è¼ƒ
    expected_majors = 3
    expected_questions = 9  # å¤§å•1: 3å•, å¤§å•2: 3å•, å¤§å•3: 3å•
    
    print(f"\næœŸå¾…å€¤ã¨ã®æ¯”è¼ƒ:")
    print(f"å¤§å•æ•°: {len(major_sections)}/{expected_majors} ({'âœ…' if len(major_sections) == expected_majors else 'âŒ'})")
    print(f"å•é¡Œæ•°: {len(questions)}/{expected_questions} ({'âœ…' if len(questions) == expected_questions else 'âŒ'})")
    
    # ãƒ†ãƒ¼ãƒæŠ½å‡ºã®ãƒ†ã‚¹ãƒˆ
    print("\n" + "="*50)
    print("é‡è¦ãªå•é¡Œã®ãƒ†ãƒ¼ãƒæŠ½å‡ºãƒ†ã‚¹ãƒˆ:")
    
    theme_extractor = ThemeExtractorV2()
    
    # é‡è¦ãªå•é¡Œã®ãƒ†ãƒ¼ãƒæŠ½å‡º
    important_questions = [
        "ä¿ƒæˆæ ½åŸ¹ã«ã¤ã„ã¦èª¬æ˜ã—ãªã•ã„ã€‚",
        "æ—¥å®‹è²¿æ˜“ã«ã¤ã„ã¦èª¬æ˜ã—ãªã•ã„ã€‚",
        "æ ¸å…µå™¨ç¦æ­¢æ¡ç´„ã«ã¤ã„ã¦èª¬æ˜ã—ãªã•ã„ã€‚",
        "å†…é–£ã®å½¹å‰²ã«ã¤ã„ã¦èª¬æ˜ã—ãªã•ã„ã€‚",
        "ç¤¾ä¼šä¿éšœåˆ¶åº¦ã«ã¤ã„ã¦èª¬æ˜ã—ãªã•ã„ã€‚",
    ]
    
    for i, question in enumerate(important_questions, 1):
        print(f"\nãƒ†ã‚¹ãƒˆ {i}: {question}")
        result = theme_extractor.extract(question)
        print(f"  ãƒ†ãƒ¼ãƒ: {result.theme}")
        print(f"  ã‚«ãƒ†ã‚´ãƒª: {result.category}")
        print(f"  ä¿¡é ¼åº¦: {result.confidence}")
        
        if result.theme:
            print(f"  âœ… ãƒ†ãƒ¼ãƒæŠ½å‡ºæˆåŠŸ")
        else:
            print(f"  âŒ ãƒ†ãƒ¼ãƒæŠ½å‡ºå¤±æ•—")
    
    # OCRãƒ†ã‚­ã‚¹ãƒˆå†…ã®é‡è¦ãªç”¨èªã®æ¤œå‡º
    print("\n" + "="*50)
    print("OCRãƒ†ã‚­ã‚¹ãƒˆå†…ã®é‡è¦ãªç”¨èªã®æ¤œå‡º:")
    
    from modules.terms_repository import TermsRepository
    repo = TermsRepository()
    
    # é‡è¦ãªç”¨èªã®æ¤œå‡º
    important_terms = ["ä¿ƒæˆæ ½åŸ¹", "æ—¥å®‹è²¿æ˜“", "æ ¸å…µå™¨ç¦æ­¢æ¡ç´„", "å†…é–£", "ç¤¾ä¼šä¿éšœ"]
    
    for term in important_terms:
        if term in ocr_text:
            terms_found = repo.find_terms_in_text(term)
            print(f"âœ… {term}: OCRãƒ†ã‚­ã‚¹ãƒˆã«å­˜åœ¨ - ç”¨èªã‚«ã‚¿ãƒ­ã‚°: {terms_found}")
        else:
            print(f"âŒ {term}: OCRãƒ†ã‚­ã‚¹ãƒˆã«å­˜åœ¨ã—ãªã„")

if __name__ == "__main__":
    test_full_ocr()
