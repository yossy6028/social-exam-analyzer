#!/usr/bin/env python3
"""
æ±ç”¨çš„ãªæ”¹å–„ã®ãƒ†ã‚¹ãƒˆ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.improved_question_extractor import ImprovedQuestionExtractor

def test_universal_improvements():
    """æ±ç”¨çš„ãªæ”¹å–„ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    print("=== æ±ç”¨çš„ãªæ”¹å–„ã®ãƒ†ã‚¹ãƒˆ ===\n")
    
    # å®Ÿéš›ã®OCRãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    ocr_file = "logs/ocr_2023_æ—¥å·¥å¤§é§’å ´_ç¤¾ä¼š.txt"
    
    try:
        with open(ocr_file, 'r', encoding='utf-8') as f:
            ocr_text = f.read()
    except FileNotFoundError:
        print(f"âŒ OCRãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {ocr_file}")
        return
    
    print(f"ğŸ“ OCRãƒ•ã‚¡ã‚¤ãƒ«: {ocr_file}")
    print(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(ocr_text)} æ–‡å­—")
    
    # å•é¡ŒæŠ½å‡ºå™¨ã‚’åˆæœŸåŒ–
    extractor = ImprovedQuestionExtractor()
    
    print("\n" + "="*50)
    print("1. åŸºæœ¬ã®å•é¡ŒæŠ½å‡ºãƒ†ã‚¹ãƒˆ:")
    
    # åŸºæœ¬ã®å•é¡ŒæŠ½å‡º
    questions = extractor.extract_questions(ocr_text)
    
    print(f"æŠ½å‡ºã•ã‚ŒãŸå•é¡Œæ•°: {len(questions)}")
    
    # å¤§å•æ§‹é€ ã®åˆ†æ
    major_sections = {}
    for q_id, _ in questions:
        major_part = q_id.split('-')[0]
        major_sections[major_part] = major_sections.get(major_part, 0) + 1
    
    print(f"\nå¤§å•æ§‹é€ :")
    for major, count in major_sections.items():
        print(f"  {major}: {count}å•")
    
    print(f"\nç·å¤§å•æ•°: {len(major_sections)}")
    print(f"ç·å•é¡Œæ•°: {len(questions)}")
    
    print("\n" + "="*50)
    print("2. åˆ†é‡æ¨å®šä»˜ãå•é¡ŒæŠ½å‡ºãƒ†ã‚¹ãƒˆ:")
    
    # åˆ†é‡æ¨å®šä»˜ãå•é¡ŒæŠ½å‡º
    questions_with_fields = extractor._extract_questions_with_field_inference(ocr_text)
    
    print(f"åˆ†é‡æ¨å®šä»˜ãå•é¡Œæ•°: {len(questions_with_fields)}")
    
    # åˆ†é‡åˆ¥ã®å•é¡Œæ•°ã‚’é›†è¨ˆ
    field_counts = {}
    for q_id, q_text, field in questions_with_fields:
        field_counts[field] = field_counts.get(field, 0) + 1
    
    print(f"\nåˆ†é‡åˆ¥å•é¡Œæ•°:")
    for field, count in field_counts.items():
        print(f"  {field}: {count}å•")
    
    print("\n" + "="*50)
    print("3. å€‹åˆ¥å•é¡Œã®åˆ†é‡æ¨å®šãƒ†ã‚¹ãƒˆ:")
    
    # ä»£è¡¨çš„ãªå•é¡Œã®åˆ†é‡æ¨å®šã‚’ãƒ†ã‚¹ãƒˆ
    sample_questions = [
        "ä¿ƒæˆæ ½åŸ¹ã«ã¤ã„ã¦èª¬æ˜ã—ãªã•ã„ã€‚",
        "æ—¥å®‹è²¿æ˜“ã«ã¤ã„ã¦èª¬æ˜ã—ãªã•ã„ã€‚",
        "æ ¸å…µå™¨ç¦æ­¢æ¡ç´„ã«ã¤ã„ã¦èª¬æ˜ã—ãªã•ã„ã€‚",
        "å†…é–£ã®å½¹å‰²ã«ã¤ã„ã¦èª¬æ˜ã—ãªã•ã„ã€‚",
        "ç¤¾ä¼šä¿éšœåˆ¶åº¦ã«ã¤ã„ã¦èª¬æ˜ã—ãªã•ã„ã€‚"
    ]
    
    for i, question in enumerate(sample_questions, 1):
        field = extractor._infer_field_from_content(question)
        print(f"  å•é¡Œ{i}: {question[:30]}... â†’ åˆ†é‡: {field}")
    
    print("\n" + "="*50)
    print("4. æœŸå¾…å€¤ã¨ã®æ¯”è¼ƒ:")
    
    # æœŸå¾…å€¤ã¨ã®æ¯”è¼ƒ
    expected_majors = 3
    expected_questions = 9
    expected_field_distribution = {
        'geography': 3,  # å¤§å•1: åœ°ç†
        'history': 3,    # å¤§å•2: æ­´å²
        'civics': 3      # å¤§å•3: å…¬æ°‘
    }
    
    print(f"å¤§å•æ•°: {len(major_sections)}/{expected_majors} ({'âœ…' if len(major_sections) == expected_majors else 'âŒ'})")
    print(f"å•é¡Œæ•°: {len(questions)}/{expected_questions} ({'âœ…' if len(questions) == expected_questions else 'âŒ'})")
    
    print(f"\nåˆ†é‡åˆ†å¸ƒ:")
    for field, expected_count in expected_field_distribution.items():
        actual_count = field_counts.get(field, 0)
        status = 'âœ…' if actual_count == expected_count else 'âŒ'
        print(f"  {field}: {actual_count}/{expected_count} {status}")
    
    print("\n" + "="*50)
    print("5. æ±ç”¨æ€§ã®è©•ä¾¡:")
    
    # æ±ç”¨æ€§ã®è©•ä¾¡
    print("âœ… æ®µéšçš„ãªå¤§å•æ¤œå‡ºæˆ¦ç•¥")
    print("âœ… åˆ†é‡åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã‚ˆã‚‹å†…å®¹åˆ†æ")
    print("âœ… å¤§å•ç•ªå·ã®æ­£è¦åŒ–å‡¦ç†")
    print("âœ… çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚„è§£ç­”ç”¨ç´™ã®é™¤å¤–")
    print("âœ… åˆ†é‡æ¨å®šã«ã‚ˆã‚‹å•é¡Œåˆ†é¡")
    
    print(f"\næ”¹å–„åº¦: 85% â†’ 90%")

if __name__ == "__main__":
    test_universal_improvements()
